{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:49.695055Z","iopub.execute_input":"2025-05-13T08:13:49.695400Z","iopub.status.idle":"2025-05-13T08:13:49.701176Z","shell.execute_reply.started":"2025-05-13T08:13:49.695375Z","shell.execute_reply":"2025-05-13T08:13:49.700252Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torchvision.models as models\nimport cv2\nimport torch.optim as optim\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sys\nsys.path.append('..')\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport fastai\n\nfrom fastai.vision.all import *\nfrom torchvision import transforms, utils\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom typing import Tuple, Union\nfrom collections import OrderedDict\nfrom torch.cuda.amp import autocast\nfrom glob import glob\nfrom sklearn.model_selection import KFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:49.703036Z","iopub.execute_input":"2025-05-13T08:13:49.703307Z","iopub.status.idle":"2025-05-13T08:13:49.726480Z","shell.execute_reply.started":"2025-05-13T08:13:49.703285Z","shell.execute_reply":"2025-05-13T08:13:49.725383Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Set up training","metadata":{}},{"cell_type":"code","source":"SEED = 85\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(SEED)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:49.727446Z","iopub.execute_input":"2025-05-13T08:13:49.727694Z","iopub.status.idle":"2025-05-13T08:13:49.744654Z","shell.execute_reply.started":"2025-05-13T08:13:49.727673Z","shell.execute_reply":"2025-05-13T08:13:49.743678Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Split and Preprocess data","metadata":{}},{"cell_type":"code","source":"labels_train_val = pd.read_csv('/kaggle/input/data/train_val_list.txt')\nlabels_train_val.columns = ['Image_Index']\nlabels_test = pd.read_csv('/kaggle/input/data/test_list.txt')\nlabels_test.columns = ['Image_Index']\ndisease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n# NIH Dataset Labels CSV File \nlabels_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nlabels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n                  'Patient_Age', 'Patient_Gender', 'View_Position',\n                  'Original_Image_Width', 'Original_Image_Height',\n                  'Original_Image_Pixel_Spacing_X',\n                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n# One hot encoding\nfor diseases in tqdm(disease_labels): \n    labels_df[diseases] = labels_df['Finding_Labels'].map(lambda result: 1 if diseases in result else 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:49.746332Z","iopub.execute_input":"2025-05-13T08:13:49.746598Z","iopub.status.idle":"2025-05-13T08:13:50.871928Z","shell.execute_reply.started":"2025-05-13T08:13:49.746576Z","shell.execute_reply":"2025-05-13T08:13:50.871209Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 14/14 [00:00<00:00, 22.42it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"labels_df['Finding_Labels'] = labels_df['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n\nnum_glob = glob('/kaggle/input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in num_glob}\n\nlabels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\nlabels_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:50.872893Z","iopub.execute_input":"2025-05-13T08:13:50.873156Z","iopub.status.idle":"2025-05-13T08:13:52.410845Z","shell.execute_reply.started":"2025-05-13T08:13:50.873134Z","shell.execute_reply":"2025-05-13T08:13:52.410076Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        Image_Index             Finding_Labels  Follow_Up_#  Patient_ID  \\\n0  00000001_000.png             [Cardiomegaly]            0           1   \n1  00000001_001.png  [Cardiomegaly, Emphysema]            1           1   \n2  00000001_002.png   [Cardiomegaly, Effusion]            2           1   \n3  00000002_000.png               [No Finding]            0           2   \n4  00000003_000.png                   [Hernia]            0           3   \n\n   Patient_Age Patient_Gender View_Position  Original_Image_Width  \\\n0           58              M            PA                  2682   \n1           58              M            PA                  2894   \n2           58              M            PA                  2500   \n3           81              M            PA                  2500   \n4           81              F            PA                  2582   \n\n   Original_Image_Height  Original_Image_Pixel_Spacing_X  ...  Emphysema  \\\n0                   2749                           0.143  ...          0   \n1                   2729                           0.143  ...          1   \n2                   2048                           0.168  ...          0   \n3                   2048                           0.171  ...          0   \n4                   2991                           0.143  ...          0   \n\n   Fibrosis  Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  Nodule  \\\n0         0         0          0                   0             1       0   \n1         0         0          0                   0             1       0   \n2         0         1          0                   0             1       0   \n3         0         0          0                   0             0       0   \n4         0         0          0                   0             0       0   \n\n   Mass  Hernia                                                  Paths  \n0     0       0  /kaggle/input/data/images_001/images/00000001_000.png  \n1     0       0  /kaggle/input/data/images_001/images/00000001_001.png  \n2     0       0  /kaggle/input/data/images_001/images/00000001_002.png  \n3     0       0  /kaggle/input/data/images_001/images/00000002_000.png  \n4     0       1  /kaggle/input/data/images_001/images/00000003_000.png  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Index</th>\n      <th>Finding_Labels</th>\n      <th>Follow_Up_#</th>\n      <th>Patient_ID</th>\n      <th>Patient_Age</th>\n      <th>Patient_Gender</th>\n      <th>View_Position</th>\n      <th>Original_Image_Width</th>\n      <th>Original_Image_Height</th>\n      <th>Original_Image_Pixel_Spacing_X</th>\n      <th>...</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Effusion</th>\n      <th>Pneumonia</th>\n      <th>Pleural_Thickening</th>\n      <th>Cardiomegaly</th>\n      <th>Nodule</th>\n      <th>Mass</th>\n      <th>Hernia</th>\n      <th>Paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>[Cardiomegaly]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>[Cardiomegaly, Emphysema]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>[Cardiomegaly, Effusion]</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000001_002.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n      <td>[No Finding]</td>\n      <td>0</td>\n      <td>2</td>\n      <td>81</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/kaggle/input/data/images_001/images/00000002_000.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>[Hernia]</td>\n      <td>0</td>\n      <td>3</td>\n      <td>81</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>/kaggle/input/data/images_001/images/00000003_000.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"unique_patients = np.unique(labels_df['Patient_ID'])\nlen(unique_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:52.411695Z","iopub.execute_input":"2025-05-13T08:13:52.411974Z","iopub.status.idle":"2025-05-13T08:13:52.420128Z","shell.execute_reply.started":"2025-05-13T08:13:52.411953Z","shell.execute_reply":"2025-05-13T08:13:52.419467Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"30805"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train-70\n# val-10\n# test-20\ntrain_val_df_patients, test_df_patients = train_test_split(unique_patients, \n                                   test_size = 0.2,\n                                   random_state = SEED,\n                                    shuffle= True\n                                   )\nlen(train_val_df_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:52.421218Z","iopub.execute_input":"2025-05-13T08:13:52.421479Z","iopub.status.idle":"2025-05-13T08:13:52.435175Z","shell.execute_reply.started":"2025-05-13T08:13:52.421448Z","shell.execute_reply":"2025-05-13T08:13:52.434477Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"24644"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train_val_df = labels_df[labels_df['Patient_ID'].isin(train_val_df_patients)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:52.436031Z","iopub.execute_input":"2025-05-13T08:13:52.436347Z","iopub.status.idle":"2025-05-13T08:13:52.482988Z","shell.execute_reply.started":"2025-05-13T08:13:52.436321Z","shell.execute_reply":"2025-05-13T08:13:52.482177Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"labels_df.shape\nprint('train_val size', train_val_df.shape[0])\nprint('test size', labels_df.shape[0] - train_val_df.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:52.483737Z","iopub.execute_input":"2025-05-13T08:13:52.483967Z","iopub.status.idle":"2025-05-13T08:13:52.488730Z","shell.execute_reply.started":"2025-05-13T08:13:52.483950Z","shell.execute_reply":"2025-05-13T08:13:52.487960Z"}},"outputs":[{"name":"stdout","text":"train_val size 89764\ntest size 22356\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"item_transforms = [\n    Resize((224, 224)),\n]\n\nbatch_transforms = [\n    Flip(),\n    Rotate(),\n    Normalize.from_stats(*imagenet_stats),\n]\n\n\ndef get_x(row):\n    return row['Paths']\n\ndef get_y(row):\n    labels = row[disease_labels].tolist()\n    return labels\n\ndblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=disease_labels)),\n                   splitter=RandomSplitter(valid_pct=0.125, seed=SEED),\n                   get_x=get_x,\n                   get_y=get_y,\n                   item_tfms=item_transforms,\n                   batch_tfms=batch_transforms\n                  )\ndls = dblock.dataloaders(train_val_df, bs=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:52.490970Z","iopub.execute_input":"2025-05-13T08:13:52.491177Z","iopub.status.idle":"2025-05-13T08:13:53.885193Z","shell.execute_reply.started":"2025-05-13T08:13:52.491161Z","shell.execute_reply":"2025-05-13T08:13:53.884440Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# CBAM-Enhanced CNN Framework","metadata":{}},{"cell_type":"markdown","source":"## CBAM Module","metadata":{}},{"cell_type":"code","source":"class BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n                              padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\nclass ChannelGate(nn.Module):\n    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n        super(ChannelGate, self).__init__()\n        self.gate_channels = gate_channels\n        self.mlp = nn.Sequential(\n            Flatten(),\n            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n            nn.ReLU(),\n            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n        )\n        self.pool_types = pool_types\n\n    def forward(self, x):\n        channel_att_sum = None\n        for pool_type in self.pool_types:\n            if pool_type == 'avg':\n                avg_pool = F.avg_pool2d(x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(avg_pool)\n            elif pool_type == 'max':\n                max_pool = F.max_pool2d(x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(max_pool)\n            elif pool_type == 'lp':\n                lp_pool = F.lp_pool2d(x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp(lp_pool)\n            elif pool_type == 'lse':\n                lse_pool = logsumexp_2d(x)\n                channel_att_raw = self.mlp(lse_pool)\n\n            if channel_att_sum is None:\n                channel_att_sum = channel_att_raw\n            else:\n                channel_att_sum = channel_att_sum + channel_att_raw\n\n        scale = torch.sigmoid(channel_att_sum).unsqueeze(2).unsqueeze(3).expand_as(x)\n        return x * scale\n\ndef logsumexp_2d(tensor):\n    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n    return outputs\n\nclass ChannelPool(nn.Module):\n    def forward(self, x):\n        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n\nclass SpatialGate(nn.Module):\n    def __init__(self):\n        super(SpatialGate, self).__init__()\n        kernel_size = 7\n        self.compress = ChannelPool()\n        self.spatial = BasicConv(2, 1, kernel_size, stride=1,\n                                 padding=(kernel_size - 1) // 2, relu=False)\n\n    def forward(self, x):\n        x_compress = self.compress(x)\n        x_out = self.spatial(x_compress)\n        scale = torch.sigmoid(x_out)\n        return x * scale\n\nclass CBAM(nn.Module):\n    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n        super(CBAM, self).__init__()\n        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n        self.no_spatial = no_spatial\n        if not no_spatial:\n            self.SpatialGate = SpatialGate()\n\n    def forward(self, x):\n        x_out = self.ChannelGate(x)\n        if not self.no_spatial:\n            x_out = self.SpatialGate(x_out)\n        return x_out","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## DenseNet121-based Feature Extractor","metadata":{}},{"cell_type":"markdown","source":"### CBAM after DenseBlock 1 2 3 4","metadata":{}},{"cell_type":"code","source":"class DenseNet121_CBAM_full(nn.Module):\n    def __init__(self, num_classes=1000, dropout=0.5):\n        super(DenseNet121_CBAM_full, self).__init__()\n        densenet = models.densenet121(pretrained=True)\n        self.features = densenet.features\n\n        self.att_block1 = CBAM(256)\n        self.att_block2 = CBAM(512)\n        self.att_block3 = CBAM(1024)\n        self.att_block4 = CBAM(1024)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.features.conv0(x)\n        x = self.features.norm0(x)\n        x = self.features.relu0(x)\n        x = self.features.pool0(x)\n\n        x = self.features.denseblock1(x)\n        x = self.att_block1(x)\n        x = self.features.transition1(x)\n\n        x = self.features.denseblock2(x)\n        x = self.att_block2(x)\n        x = self.features.transition2(x)\n\n        x = self.features.denseblock3(x)\n        x = self.att_block3(x)\n        x = self.features.transition3(x)\n\n        x = self.features.denseblock4(x)\n        x = self.att_block4(x)\n\n        x = self.features.norm5(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\nmodel_dense_cbam_full =  DenseNet121_CBAM_full(\n    num_classes=14,\n    dropout=0.5,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:53.885994Z","iopub.execute_input":"2025-05-13T08:13:53.886235Z","iopub.status.idle":"2025-05-13T08:13:58.013392Z","shell.execute_reply.started":"2025-05-13T08:13:53.886212Z","shell.execute_reply":"2025-05-13T08:13:58.012651Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n100%|██████████| 528M/528M [00:02<00:00, 234MB/s] \n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### CBAM after DenseBlock 3 4","metadata":{}},{"cell_type":"code","source":"class DenseNet121_CBAM(nn.Module):\n    def __init__(self, num_classes=1000, dropout=0.5):\n        super(DenseNet121_CBAM, self).__init__()\n        densenet = models.densenet121(pretrained=True)\n        self.features = densenet.features\n\n        self.att_block3 = CBAM(1024)\n        self.att_block4 = CBAM(1024)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.features.conv0(x)\n        x = self.features.norm0(x)\n        x = self.features.relu0(x)\n        x = self.features.pool0(x)\n\n        x = self.features.denseblock1(x)\n        x = self.features.transition1(x)\n\n        x = self.features.denseblock2(x)\n        x = self.features.transition2(x)\n\n        x = self.features.denseblock3(x)\n        x = self.att_block3(x)\n        x = self.features.transition3(x)\n\n        x = self.features.denseblock4(x)\n        x = self.att_block4(x)\n\n        x = self.features.norm5(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\nmodel_dense_cbam =  DenseNet121_CBAM(\n    num_classes=14,\n    dropout=0.5,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CBAM after DenseBlock 4","metadata":{}},{"cell_type":"code","source":"class DenseNet121_CBAM_after(nn.Module):\n    def __init__(self, num_classes=1000, dropout=0.5):\n        super(DenseNet121_CBAM_after, self).__init__()\n        densenet = models.densenet121(pretrained=True)\n        self.features = densenet.features\n\n        self.cbam = CBAM(1024)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.cbam(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\nmodel_dense_cbam_after =  DenseNet121_CBAM_after(\n    num_classes=14,\n    dropout=0.5,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## VGG16-based Feature Extractor","metadata":{}},{"cell_type":"markdown","source":"### CBAM after VGGBlock 1 2 3 4 5","metadata":{}},{"cell_type":"code","source":"class VGG_CBAM_full(nn.Module):\n    def __init__(self, num_classes, dropout=None):\n        super(VGG_CBAM_full, self).__init__()\n        net = models.vgg16_bn(pretrained=True)\n   \n        self.conv_block1 = nn.Sequential(\n            *list(net.features.children())[0:6],\n            CBAM(gate_channels=64)\n        )\n        self.conv_block2 = nn.Sequential(\n            *list(net.features.children())[7:13],\n            CBAM(gate_channels=128)\n        )\n        self.conv_block3 = nn.Sequential(\n            *list(net.features.children())[14:23],\n            CBAM(gate_channels=256)\n        )\n        self.conv_block4 = nn.Sequential(\n            *list(net.features.children())[24:33],\n            CBAM(gate_channels=512)\n        )\n        self.conv_block5 = nn.Sequential(\n            *list(net.features.children())[34:43],\n            CBAM(gate_channels=512)\n        )\n        self.pool = nn.AvgPool2d(7, stride=1)\n        self.dpt = nn.Dropout(dropout) if dropout is not None else None\n        # The classifier now expects concatenated features from global pooling and cross-attention outputs.\n        self.cls = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n\n        self.reset_parameters(self.cls)\n\n    def reset_parameters(self, module):\n        for m in module.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0.)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1.)\n                nn.init.constant_(m.bias, 0.)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0., 0.01)\n                nn.init.constant_(m.bias, 0.)\n\n    def forward(self, x):\n        # Pass input through each VGG block (with CBAM enhancement)\n        block1 = self.conv_block1(x)              # output channels: 64\n        pool1 = F.max_pool2d(block1, 2, 2)          # /2\n        block2 = self.conv_block2(pool1)            # output channels: 128\n        pool2 = F.max_pool2d(block2, 2, 2)          # /4\n        block3 = self.conv_block3(pool2)            # output channels: 256\n        pool3 = F.max_pool2d(block3, 2, 2)          # /8\n        block4 = self.conv_block4(pool3)            # output channels: 512\n        pool4 = F.max_pool2d(block4, 2, 2)          # /16\n        block5 = self.conv_block5(pool4)            # output channels: 512\n        pool5 = F.max_pool2d(block5, 2, 2)          # /32\n\n        N = pool5.size(0)\n        # Global features from pool5 using average pooling\n        g = self.pool(pool5).view(N, 512)\n\n        if self.dpt is not None:\n            g = self.dpt(g)\n\n        # Final classification\n        out = self.cls(g)\n        return out\n\nmodel_vgg_cbam_full = VGG_CBAM_full(14, 0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CBAM after VGGBlock 3 4 5","metadata":{}},{"cell_type":"code","source":"class VGG_CBAM(nn.Module):\n    def __init__(self, num_classes, dropout=None):\n        super(VGG_CBAM, self).__init__()\n        net = models.vgg16_bn(pretrained=True)\n        # Wrap each conv block with CBAM.\n        # Note: Adjust gate_channels based on the output channels of each block.\n        self.conv_block1 = nn.Sequential(\n            *list(net.features.children())[0:6],\n        )\n        self.conv_block2 = nn.Sequential(\n            *list(net.features.children())[7:13],\n        )\n        self.conv_block3 = nn.Sequential(\n            *list(net.features.children())[14:23],\n            CBAM(gate_channels=256)\n        )\n        self.conv_block4 = nn.Sequential(\n            *list(net.features.children())[24:33],\n            CBAM(gate_channels=512)\n        )\n        self.conv_block5 = nn.Sequential(\n            *list(net.features.children())[34:43],\n            CBAM(gate_channels=512)\n        )\n        self.pool = nn.AvgPool2d(7, stride=1)\n        self.dpt = nn.Dropout(dropout) if dropout is not None else None\n        # The classifier now expects concatenated features from global pooling and cross-attention outputs.\n        self.cls = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n\n        self.reset_parameters(self.cls)\n\n    def reset_parameters(self, module):\n        for m in module.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0.)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1.)\n                nn.init.constant_(m.bias, 0.)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0., 0.01)\n                nn.init.constant_(m.bias, 0.)\n\n    def forward(self, x):\n        # Pass input through each VGG block (with CBAM enhancement)\n        block1 = self.conv_block1(x)              # output channels: 64\n        pool1 = F.max_pool2d(block1, 2, 2)          # /2\n        block2 = self.conv_block2(pool1)            # output channels: 128\n        pool2 = F.max_pool2d(block2, 2, 2)          # /4\n        block3 = self.conv_block3(pool2)            # output channels: 256\n        pool3 = F.max_pool2d(block3, 2, 2)          # /8\n        block4 = self.conv_block4(pool3)            # output channels: 512\n        pool4 = F.max_pool2d(block4, 2, 2)          # /16\n        block5 = self.conv_block5(pool4)            # output channels: 512\n        pool5 = F.max_pool2d(block5, 2, 2)          # /32\n\n        N = pool5.size(0)\n        # Global features from pool5 using average pooling\n        g = self.pool(pool5).view(N, 512)\n\n        if self.dpt is not None:\n            g = self.dpt(g)\n\n        # Final classification\n        out = self.cls(g)\n        return out\n\nmodel_vgg_cbam = VGG_CBAM(14, 0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CBAM after VGGBlock 5","metadata":{}},{"cell_type":"code","source":"class VGG16_CBAM_after(nn.Module):\n    def __init__(self, num_classes, dropout=0.5):\n        super(VGG16_CBAM_after, self).__init__()\n        base = models.vgg16_bn(pretrained=True)\n\n        self.features = base.features\n\n        self.cbam = CBAM(512)\n\n        # Classification head\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(dropout) if dropout else nn.Identity()\n        self.classifier = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)      \n        x = self.cbam(x)          \n        x = self.pool(x).flatten(1)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\nmodel_vgg_cbam_after = VGG16_CBAM_after(num_classes=14, dropout=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Stage 2","metadata":{}},{"cell_type":"code","source":"learn = Learner(\n    dls,\n    model_vgg_cbam_after, # adjust for suitable model \n    metrics=[accuracy_multi, F1ScoreMulti(), RocAucMulti()],\n    cbs=[\n        SaveModelCallback(monitor='valid_loss', fname='best_model', min_delta=0.0001, with_opt=True),\n        EarlyStoppingCallback(monitor='valid_loss', min_delta=0.001, patience=5),\n        ShowGraphCallback()\n    ]\n)\nlearn = learn.load('')  # weight of stage 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn.unfreeze()\nlearn.model\nsum(p.numel() for p in learn.model.parameters() if p.requires_grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:13:58.065632Z","iopub.status.idle":"2025-05-13T08:13:58.065967Z","shell.execute_reply.started":"2025-05-13T08:13:58.065784Z","shell.execute_reply":"2025-05-13T08:13:58.065798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn.fit_one_cycle(10, slice(2e-5, 8e-5))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}